---
layout: post
title: "[ML/stat] Indexing by Latent Semantic Analysis"
categories: doc
tags: ['ml', 'stat']
comments: true
use_math: true
---

*Indexing by Latent Semantic Analysis(1990)* 페이퍼를 읽고 나름대로 공부한 내용입니다 😀

## 1. Indexing and Retrieval

이 논문에서는 문서 검색 문제의 이슈를 크게 **synonymy**에 의한 것과  **polysemy**에 의한 것으로 분류한다. **Synonymy** 는 서로 다른 언어적 표현들이 유사한 의미를 갖는 말한다. 같은 의미를 가리키는 다른 표현의 사용으로 인해, 실제로 관계가 있는 문서가 관계가 없는 문서로 분류될 수 있다. 즉 **Synonymy**는 FN 케이스를 발생시켜 재현율을 떨어뜨리는 원인이 된다. **Polysemy**는 반대로 하나의 어휘가 여러 의미를 가리킬 수 있다는 뜻이다. 이 경우에는 실제로 관계가 없는 문서임에도 불구하고 같은 어휘가 사용되었다는 이유로 인해 관계가 있는 문서로 분류될 가능성이 높아진다. 즉 **Polysemy**는  FP 케이스를 발생시켜 정밀도를 떨어뜨리는 원인이 된다.

## 2. Latent Semantic Indexing

이 논문에서 제안하는 LSI(latent semantic indexing)은 **Synonymy** 이슈에 초점을 맞춘 방법이다. 즉 서로 다른 단어들로 표현된 검색어들과 문서들 뒤에 숨겨진 공통의 잠재적 의미를 찾아내는 것이다. 이를 통해 검색어와 문서에 사용된 어휘가 정확히 일치하지 않는 경우에도 양자의 의미가 통한다면 매칭을 시켜줄 수 있다. 그렇다면 잠재적인 의미라는 것을 어떻게 모델링할 수 있을까? 분석은 term-document 행렬에서 시작한다. 


```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

plt.style.use("seaborn-white")
```


```python
X = np.array([
    [1, 0, 0, 1, 0, 0, 0, 0, 0],
    [1, 0, 1, 0, 0, 0, 0, 0, 0],
    [1, 1, 0, 0, 0, 0, 0, 0, 0],
    [0, 1, 1, 0, 1, 0, 0, 0, 0],
    [0, 1, 1, 2, 0, 0, 0, 0, 0],
    [0, 1, 0, 0, 1, 0, 0, 0, 0],
    [0, 1, 0, 0, 1, 0, 0, 0, 0],
    [0, 0, 1, 1, 0, 0, 0, 0, 0],
    [0, 1, 0, 0, 0, 0, 0, 0, 1],
    [0, 0, 0, 0, 0, 1, 1, 1, 0],
    [0, 0, 0, 0, 0, 0, 1, 1, 1],
    [0, 0, 0, 0, 0, 0, 0, 1, 1],
])
columns = [f"c{i}" for i in range(1, 6)] + [f"m{i}" for i in range(1, 5)]
index = ["human", "interface", "computer", "user", "system", "response", "time", "EPS", "survey", "trees", "graph", "minors"]
X = pd.DataFrame(X, columns=columns, index=index)
```

Category | Colnames | Titles
--- | --- | ---
Human-computer interaction| c1 | ***Human*** maching ***interface*** for Lab ABC ***computer*** applications
Human-computer interaction| c2 | A ***survey*** of user opinion of ***computer system response time*** 
Human-computer interaction| c3 | The ***EPS user interface*** management ***system***
Human-computer interaction| c4 | ***System*** and ***human system*** engineering testing of ***EPS***
Human-computer interaction| c5 | Relation of ***user***-perceived ***response time*** to error measurement
Graph| m1 | The generation of random, binary, unordered ***trees***
Graph| m2 | The intersection ***graph*** of paths in ***trees***
Graph| m3 | ***Graph minors*** IV: Widths of ***trees*** and well-quasi-ordering
Graph| m4 | ***Graph minors***: A ***survey***

논문에 사용된 예시를 보자. Term-document 행렬의 \\(i, j \\) 셀 값은 \\( i \\) 번째 텀이 \\( j \\) 번째 문서 안에 등장하는 빈도를 나타낸다. (이 예시에서는 두 개 이상의 문서에 등장하는 단어들만을 대상으로 행렬을 만들었다). 컬럼의 c1\~c5 human-computer interaction 에 관한 논문들이고, m1\~m4는 그래프에 관한 논문들이다. 행 벡터들 간의 유사도는 곧 텀 간의 유사도를 나타내고, 열 벡터들 간의 유사도는 문서들 간의 유사도를 나타낸다는 점을 쉽게 알 수 있다.


```python
X
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
      <th>c4</th>
      <th>c5</th>
      <th>m1</th>
      <th>m2</th>
      <th>m3</th>
      <th>m4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>human</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>interface</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>computer</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>user</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>system</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>response</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>time</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>EPS</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>survey</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>trees</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>graph</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>minors</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



하지만 현실적으로 사용자의 질의와 문서의 제목이 완벽히 일치하기는 어렵다. 문서를 검색하는 사용자들은 유사한 내용에 대해 각기 다른 키워드를 사용해서 검색을 할 것이고, 논문을 쓰는 저자들 역시 마찬가지로 유사한 내용에 대해 다른 제목을 뽑을 것이다. 공통의 의미는 분명 존재하지만, 개별적인 문서와 쿼리는 이를 온전히 표현하지 못하는 불완전한 기표이다. 하지만 여러 문서들, 여러 단어들 간의 관계를 들여다보면 문서와 텀의 의미를 보다 정확하게 파악할 수있다. 가령 **황금올리브**와 **황올**이 각각 100건의 문서에 포함되었고, **황금올리브**를 포함하는 문서 중 **황올**도 포함하는 문서가 95건이라고 가정해보자. 우리는 둘 사이에 모종의 연관이 존재한다는 사실을 알 수 있고, **황금올리브**을 검색한 사용자에게 **황올**을 포함하는 문서 역시 보여줄 수 있을 것이다.

![](https://i.pinimg.com/originals/a8/e9/46/a8e94600f641ef262ab3e5700ef3b991.jpg)

## 3. SVD or Two-Mode Factor Analysis

$$
\begin{align}
X &= T_0S_0D_0' \\
&=
\begin{bmatrix}
\mathbf{t_1} \space \mathbf{t_2} \space \cdots \space \mathbf{t_r}
\end{bmatrix}
\begin{bmatrix}
    \sigma_{1} & & \\
    & \ddots & \\
    & & \sigma_{r}
  \end{bmatrix}
\begin{bmatrix}
\mathbf{d_1}' \\ 
\mathbf{d_2}' \\ 
\vdots \\
\mathbf{d_r}'
\end{bmatrix}
\\
&= \sigma_1 \mathbf{t_1} \mathbf{d_1}' + \sigma_2 \mathbf{t_2} \mathbf{d_2}'  + \cdots + \sigma_r \mathbf{t_r} \mathbf{d_r}'
\end{align}
$$

문서와 문서, 텀과 텀의 관계를 표현하기 위해 이 논문에서 선택한 방법은 특이값 분해이다. Term-document 행렬 \\( X \in \mathbb{R}^{t \times d} \\)가 랭크 \\( r\\) 을 가진다고 하자. 행렬은 특이값 분해는 위 식처럼 일종의 선형 결합으로 표현할 수 있다. SVD에서 특이값은 크기 순으로 \\( \sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0 \\) 처럼 배열하는 것이 관례이다. 따라서 특이값이 작은 뒤쪽 항들은 잘라내더라도 행렬의 값에는 큰 변화가 없을 것 같다. 행렬 \\( X \in \mathbb{R}^{t \times d} \\)에 Truncated SVD를 적용해서 랭크 \\( k (k < r) \\) 의 행렬로 근사해보면 다음과 같이 쓸 수 있다. 이 결과는 기존의 행렬 \\( X \\) 를 근사하는 랭크 \\( k \\) 행렬 중 가장 작은 제곱오차를 갖는 행렬임을 증명할 수 있다.

$$
\begin{align}
X & \approx \hat{X} \\
&= \sigma_1 \mathbf{t_1} \mathbf{d_1}' + \sigma_2 \mathbf{t_2} \mathbf{d_2}'  + \cdots + \sigma_k \mathbf{t_k} \mathbf{d_k}' \\
&=
\begin{bmatrix}
\mathbf{t_1} \space \mathbf{t_2} \space \cdots \space \mathbf{t_k}
\end{bmatrix}
\begin{bmatrix}
    \sigma_{1} & & \\
    & \ddots & \\
    & & \sigma_{k}
  \end{bmatrix}
\begin{bmatrix}
\mathbf{d_1}' \\ 
\mathbf{d_2}' \\ 
\vdots \\
\mathbf{d_k}'
\end{bmatrix} \\
&= TSD'
\end{align}
$$


```python
# rank 2 approximation
k = 2
T, S, Dt = np.linalg.svd(X) # X = TSD'
D = Dt.T
T = T[:, :k]
S = np.diag(S[:2])
D = D[:, :k]
Xhat = pd.DataFrame(T.dot(S).dot(D.T), index=X.index, columns=X.columns)
Xhat
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
      <th>c4</th>
      <th>c5</th>
      <th>m1</th>
      <th>m2</th>
      <th>m3</th>
      <th>m4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>human</th>
      <td>0.162058</td>
      <td>0.400498</td>
      <td>0.378955</td>
      <td>0.467566</td>
      <td>0.175954</td>
      <td>-0.052655</td>
      <td>-0.115143</td>
      <td>-0.159102</td>
      <td>-0.091838</td>
    </tr>
    <tr>
      <th>interface</th>
      <td>0.140585</td>
      <td>0.369801</td>
      <td>0.328996</td>
      <td>0.400427</td>
      <td>0.164972</td>
      <td>-0.032815</td>
      <td>-0.070569</td>
      <td>-0.096768</td>
      <td>-0.042981</td>
    </tr>
    <tr>
      <th>computer</th>
      <td>0.152449</td>
      <td>0.505004</td>
      <td>0.357937</td>
      <td>0.410107</td>
      <td>0.236232</td>
      <td>0.024217</td>
      <td>0.059781</td>
      <td>0.086857</td>
      <td>0.123966</td>
    </tr>
    <tr>
      <th>user</th>
      <td>0.258049</td>
      <td>0.841123</td>
      <td>0.605720</td>
      <td>0.697357</td>
      <td>0.392318</td>
      <td>0.033118</td>
      <td>0.083245</td>
      <td>0.121772</td>
      <td>0.187380</td>
    </tr>
    <tr>
      <th>system</th>
      <td>0.448790</td>
      <td>1.234365</td>
      <td>1.050861</td>
      <td>1.265796</td>
      <td>0.556331</td>
      <td>-0.073790</td>
      <td>-0.154694</td>
      <td>-0.209598</td>
      <td>-0.048880</td>
    </tr>
    <tr>
      <th>response</th>
      <td>0.159554</td>
      <td>0.581682</td>
      <td>0.375219</td>
      <td>0.416898</td>
      <td>0.276541</td>
      <td>0.055904</td>
      <td>0.132218</td>
      <td>0.188911</td>
      <td>0.216908</td>
    </tr>
    <tr>
      <th>time</th>
      <td>0.159554</td>
      <td>0.581682</td>
      <td>0.375219</td>
      <td>0.416898</td>
      <td>0.276541</td>
      <td>0.055904</td>
      <td>0.132218</td>
      <td>0.188911</td>
      <td>0.216908</td>
    </tr>
    <tr>
      <th>EPS</th>
      <td>0.218463</td>
      <td>0.549581</td>
      <td>0.510960</td>
      <td>0.628058</td>
      <td>0.242536</td>
      <td>-0.065411</td>
      <td>-0.142521</td>
      <td>-0.196612</td>
      <td>-0.107913</td>
    </tr>
    <tr>
      <th>survey</th>
      <td>0.096906</td>
      <td>0.532064</td>
      <td>0.229914</td>
      <td>0.211754</td>
      <td>0.266525</td>
      <td>0.136756</td>
      <td>0.314621</td>
      <td>0.444441</td>
      <td>0.424969</td>
    </tr>
    <tr>
      <th>trees</th>
      <td>-0.061254</td>
      <td>0.232108</td>
      <td>-0.138898</td>
      <td>-0.265646</td>
      <td>0.144925</td>
      <td>0.240421</td>
      <td>0.546147</td>
      <td>0.767374</td>
      <td>0.663709</td>
    </tr>
    <tr>
      <th>graph</th>
      <td>-0.064677</td>
      <td>0.335281</td>
      <td>-0.145641</td>
      <td>-0.301406</td>
      <td>0.202756</td>
      <td>0.305726</td>
      <td>0.694893</td>
      <td>0.976611</td>
      <td>0.848750</td>
    </tr>
    <tr>
      <th>minors</th>
      <td>-0.043082</td>
      <td>0.253906</td>
      <td>-0.096667</td>
      <td>-0.207858</td>
      <td>0.151913</td>
      <td>0.221227</td>
      <td>0.502945</td>
      <td>0.706912</td>
      <td>0.615504</td>
    </tr>
  </tbody>
</table>
</div>



이제 \\( k \\) 차원 행렬  \\( \hat{X}=TSD' \\) 를 통해 **문서와 단어를 같은 \\( k \\) 차원의 벡터로 표현**할 것이다. 문서 인덱싱과 검색이라는 목적을 생각해볼 때, 근사하는 차원이 너무 작거나 너무 커서는 안된다. 차원은 문서 간의 의미 관계를 풍부하게 표현할 있도록 충분히 커야 하지만, 지나치게 큰 공간에서는 유의미한 유사성을 발견하기가 어려워진다.

\\( T, D \\) 가 직교행렬이고 \\( S \\) 가 대각행렬이므로 아래의 두 식이 성립한다. **\\( \hat{X}{'}\hat{X} \\) 의 \\( i, j \\) 셀은  \\( \hat{X} \\) 의 \\( i \\) 행과 \\( j \\) 행의 내적으로, 두 텀의 유사도를 나타낸다. 따라서 \\( TS \\) 행렬의 행끼리 내적한 결과 역시 두 텀의 유사도를 나타낸다. 동일하게 \\( DS \\) 행렬의 행끼리 내적한 결과는 두 문서의 유사도를 나타낸다. \\( TS, DS \\) 의 행 벡터들이 \\( k \\) 차원의 벡터이므로 둘을 같은 공간에 표현할 수 있다.**

$$
\hat{X}\hat{X}' = TS^2T{'} = TS(TS)' \\
\hat{X}'\hat{X} = DS^2D{'} = DS(DS)' \\
$$

\\( k=2 \\) 로 특이값 분해를 해서 텀과 문서의 좌표를 그려보자. 산점도를 그려보면 논문의 그림을 y축으로 뒤집은 결과가 나온다. 아마 부호에는 별 의미가 없으니 논문에서는 보기 편하도록 x 값을 양수로 바꿔준 것 같다. 아무튼 중요한 점은, 인간-컴퓨터 상호작용 관련 논문들과 그래프 관련 논문들이 직교하는 방향으로 표현되었다는 점이다. 텀 역시도 마찬가지의 경향을 보인다.


```python
coords = pd.DataFrame(
    np.vstack([T.dot(S), D.dot(S)]), columns=["x", "y"], index = X.index.to_list() + X.columns.to_list()
).assign(label=["term"]*T.shape[0] + ["doc"]*D.shape[0])
```


```python
fig, ax = plt.subplots(nrows=1, figsize=(10,10))
plt.vlines(0, -.8, 1.8, colors="gray", linewidths=1)
plt.hlines(0, -3, .1, colors="gray", linewidths=1)
sns.scatterplot(data=coords, x="x", y="y", palette="Set1", hue="label", style="label", s=150, alpha=0.7)
for x, y, idx in zip(coords.x, coords.y, coords.index):
    plt.text(x +.05, y-0.01, idx, va="center", ha="left", fontsize=12, alpha=0.8)
plt.legend(loc="upper left", fontsize=20)
plt.show()
```


    
![png](/assets/img/docs/2021-02-04-LSI_files/2021-02-04-LSI_11_0.png)
    


이 공간에서 텀과 텀, 문서와 문서의 내적은 둘 사이의 유사도를 나타낸다. 그렇다면 텀과 문서 간의 유사도를 측정하는 것도 가능할까? 텀과 문서의 유사도는 기본적으로 \\( \hat{X} \\) 의 각 셀이 가지는 값이고, 이는 \\( TS^\frac{1}{2} \\) 과 \\( (DS^\frac{1}{2})' \\)의 행 내적과 같다. 즉 **같은 공간에서 \\( TS \\)와 \\( DS \\) 내적은 문서와 텀의 유사도를 직접 반영하지는 못한다. 하지만 \\( S \\) 가 대각행렬이므로 각 축을 \\( S^\frac{1}{2} \\) 로 스케일링 한 후 내적하면 문서와 텀 사이의 유사도를 구할 수 있다.**

$$
\hat{X} = TSD' = TS^\frac{1}{2} (DS^\frac{1}{2})'
$$

## 4. Finding Representations for Pseudo-Documents

$$
\hat{X} = TSD' \\
\hat{X_q} = TSD_q' \\
\therefore D_q = \hat{X_q}'TS^{-1}, \space D_qS = \hat{X_q}'T
$$

텀과 문서를 \\( k \\) 차원 공간에 표현함으로써 기존에 가지고 있던 기존에 가지고 있던 문서와 텀에 대한 인덱싱이 완료되었다. 이제 사용자로부터 질의를 받아서 매칭되는 문서를 반환해주는 과정을 살펴보도록 하자. 쿼리와 문서를 비교하기 위해서는 우선 쿼리를 동일한 \\( k \\) 차원의 문서 벡터로 표현해야 한다. 그 후 실제 문서 벡터와 유사도를 측정하면 매칭되는 문서를 찾아낼 수 있을 것이다. 사용자로부터 쿼리 \\( q \\) 가 들어왔다고 가정해보자. 쿼리는 0개 이상의 텀을 포함하는 의사 문서(pseudo document)로 볼 수 있다. 이미 가지고 있는 텀의 목록에 의해 이들이 쿼리에 나타나는 빈도를 \\( X_q \\) 로 표현할 수 있다. 우리는 여기에서 출발해 쿼리의 의사 문서 표현을 유도하고 싶다. 사실 유도랄 것도 없고, 특이값 분해 \\( \hat{X} = TSD' \\) 에서 \\( X \\) 와 \\( D \\) 대신 \\( X_q \\) 와 \\( D_q \\) 를 넣어주면 된다.

사용자로부터 "***human computer*** interaction" 이라는 쿼리가 들어왔다고 가정해보자. 인덱스 텀 중 ***human, computer***를 각각 한 번씩 포함하므로 쿼리의 의사문서벡터는 아래 코드처럼 표현된다. 인간-컴퓨터 상호작용 관련 논문들과 비슷한 방향으로 표현되었음을 알 수 있다. 이제 이 공간에서 유사도를 계산해 가장 가까운 문서 몇 개를 반환해주면 된다. 벡터 표현은 내적으로 유도했지만 논문에서 최종적으로는 코사인 유사도를 사용하는 것 같다. 단어가 한 문서에서 몇 번이나 등장했는지의 구체적인 빈도보다는 해당 단어를 포함하는지의 여부, 그리고 어떤 단어들과 함께 등장하는지를 중요하게 보겠다는 뜻인 것 같다.

> To return a set of porential cadidate documents, the pseudo-document formed from a query is compared against all documents, and **those with the highest cosines, that is the nearest vectors, are returned.**


```python
Xq = np.array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]).reshape((-1, 1))
Dq = Xq.T.dot(T).dot(np.linalg.inv(S))
DqS = Dq.dot(S)
```



    
![png](/assets/img/docs/2021-02-04-LSI_files/2021-02-04-LSI_15_0.png)
    


