---
layout: post
title: "[국민청원] 청와대 국민청원 토픽 모델링"
categories: [doc, project]
tags: petition
comments: true
---

청와대 국민청원 게시판에 올라온 글들을 대상으로 LDA 기반 토픽 모델링을 하는 과정입니다. 정의라는 가치가 주로 어떤 주제들과 관련을 맺고 있는지를 탐구하기 위해서 이러한 모델링을 진행하였습니다. 앞서 진행한 Word2Vec 모델에서 정의와 가장 유사한 단어 50개를 추출한 후, 해당 단어들을 포함하는 문서들만을 대상으로 토픽 모델링을 진행하였습니다. 코드는 이수진님이 작성하였습니다. 

먼저 사전에 준비해놓은 `custom` 모듈을 불러옵니다. 커스텀 모듈의 코드는 문서 가장 아래에 정리해두었습니다. 이후 키워드와 불용어를 지정해줍니다. 이후 타겟 단어들을 포함하는 문서들만을 필터링해줍니다.

```python
from custom import * # 수진님이 만들어두신 함수들

#키워드 및 불용어 지정
KEYWORD = '정의'
stop_words = [KEYWORD, '국민', '대한민국', '한국', '정부', '대통령', '문재인', '사회', '사람', '문제', '청원', '모든', '대한', '지금', '현재', '나라', '국가', '우리', '저희', '관련', '생각', '까지', '면서', '부터', '대해', '때문', '위해', '대로', '이나', '해주', '도록', '이상', '정말', '내용', '당하', '아무', '보고', '래서', '더니', '려면', '고하', '처럼', '또한']

data = pd.read_csv("data/data.csv")
bools = data.Content.apply(lambda doc: any([x in doc for x in np.append(keywords.keyword.values, "정의")])) # 정의 + Top50 단어들을 포함하는 문서
justice = data[bools]
```

필터링된 데이터에서 명사를 추출하고, 토픽 갯수별로 coherence value를 계산해줍니다. Coherence value가 낮으면 좋지만, 너무 많은 수의 토픽으로 분류할 경우 분석이 어려워질 수 있으므로 플롯을 통해 최적의 토픽 갯수를 확인한 후 LDA 모델을 훈련하고 시각화 결과를 저장해줍니다.

```python
docs_nouns = [mecab.nouns(doc) for doc in justice.Content] # 포매팅(명사추출)
docs_filtered = [[term for term in doc if term not in stop_words and len(term)>1] for doc in docs_nouns] # 불용어 필터
article_indexes = [k for k in range(len(docs_filtered))]
corpus, dictionary = build_doc_word_matrix(docs_filtered)
# corpus = dtm based on frequency

print('Number of unique tokens: %d' % len(dictionary))
print('Number of documents: %d' % len(corpus))

model_list, coherence_values = compute_coherence_values(
    dictionary=dictionary, corpus=corpus, texts=docs_filtered, start=2, limit=40, step=6
)  #start, limit, step 조정

import matplotlib.pyplot as plt
limit=40; start=2; step=6;
x = range(start, limit, step)
plt.plot(x, coherence_values)
plt.xlabel("Num Topics")
plt.ylabel("Coherence score")
plt.legend(("coherence_values"), loc='best')
plt.show()

#토픽 수와 토픽 키워드 수 지정
NUM_TOPICS = 14

#모델 시행
lda_model = models.ldamodel.LdaModel(
    corpus,
    num_topics=NUM_TOPICS,
    id2word=dictionary,
    alpha='auto'
)

lda_model.save("./LDA/top50.lda")
```

아래는 커스텀 모듈의 내용입니다.

```python
from gensim import corpora
from gensim import models
from gensim.models import CoherenceModel
from collections import defaultdict
import pyLDAvis.gensim as gensimvis
import pyLDAvis

def get_filtered_words(docs):
    term_fre_dict = defaultdict(int)
    doc_fre_dict = defaultdict(int)

    for doc in docs:
        for word in doc:
            term_fre_dict[word] += 1
        for word in set(doc):
            doc_fre_dict[word] += 1
    
    max_doc_frequency = 1000
    min_doc_frequency = 3
    max_term_frequency = 7000
    min_term_frequency = 5
    
    doc_frequency_filtered = {k:v for k, v in doc_fre_dict.items() if ((v>=min_doc_frequency) and (v <= max_doc_frequency))}
    term_frequency_filtered = {k:v for k, v in term_fre_dict.items() if ((v>=min_term_frequency) and (v <= max_term_frequency))}
    both_satisfied = {k:v for k, v in term_frequency_filtered.items() if k in doc_frequency_filtered}
    
    return both_satisfied

def get_highest_topic(topic_list):
    highest_topic = 100
    highest_prob = 0
    for topic, prob in topic_list:
        if prob > highest_prob:
            highest_prob = prob
            highest_topic = topic
    return highest_topic, highest_prob

def build_doc_word_matrix(docs):
    dictionary = corpora.Dictionary(docs)
    corpus = []
    for doc in docs:
        bow = dictionary.doc2bow(doc)
        corpus.append(bow)

    return corpus, dictionary

def print_topic_words(model):
    f = open(f'{KEYWORD}_LDA_.txt','w')
    for topic_id in range(model.num_topics):
        word_probs = model.show_topic(topic_id, NUM_TOPIC_WORDS)
        print("Topic ID: {}".format(topic_id))
        f.write(str(topic_id)+'\n')
        for word, prob in word_probs:
            print("\t{}\t{}".format(word, prob))
            f.write(str(word)+'\t'+str(prob)+'\n')
        print("\n")
    f.close()

def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):
    """
    Compute c_v coherence for various number of topics

    Parameters:
    ----------
    dictionary : Gensim dictionary
    corpus : Gensim corpus
    texts : List of input texts
    limit : Max num of topics

    Returns:
    -------
    model_list : List of LDA topic models
    coherence_values : Coherence values corresponding to the LDA model with respective number of topics
    """
    coherence_values = []
    model_list = []
    for num_topics in range(start, limit, step):
        model = models.ldamodel.LdaModel(corpus, num_topics=num_topics,
                        id2word=dictionary,
                        alpha='auto')
        model_list.append(model)
        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')
        coherence_values.append(coherencemodel.get_coherence())

    return model_list, coherence_values
```